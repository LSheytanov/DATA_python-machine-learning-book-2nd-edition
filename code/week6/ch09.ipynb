{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Python Machine Learning 2nd Edition* by [Sebastian Raschka](https://sebastianraschka.com), Packt Publishing Ltd. 2017\n",
    "\n",
    "Code Repository: https://github.com/trungngv/python-machine-learning-book-2nd-edition\n",
    "\n",
    "Code License: [MIT License](https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Deploying a Machine Learning Model\n",
    "\n",
    "Slides: [https://](https://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Week 5 recap - Training a model for movie review classification](#Chapter-6-recap---Training-a-model-for-movie-review-classification)\n",
    "\n",
    "- [Serializing fitted scikit-learn estimators](#Serializing-fitted-scikit-learn-estimators)\n",
    "- [Deploying model as a Flask web application](#Deploying-model-as-a-Flask-web-application)\n",
    "    - [Local deployment](#Local-deployment)\n",
    "    - [Cloud deployment with Heroku](#Cloud-deployment-with-Heroku)\n",
    "- [Using Amazon SageMaker](#Using-Amazon-SageMaker)\n",
    "- [Cognitive services API](#Cognitive-Services)\n",
    "    - [API made easy with Postman](#API-made-easy-with-Postman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 recap - Training a model for movie review classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is a recap of the logistic regression model that was trained in the last section of Chapter 5. Execute the folling code blocks to train a model that we will serialize in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('movie_data.csv.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.sentiment, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feat', HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='ignore', dtype=<class 'numpy.float64'>,\n",
       "         encoding='utf-8', input='content', lowercase=True,\n",
       "         n_features=2097152, ngram_range=(1, 2), non_negative=False,\n",
       "         norm='l2', pr...lty='l2', power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         lowercase=True,\n",
    "                         stop_words='english',\n",
    "                         ngram_range=(1,2))\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('feat', vect),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If you are using scikit-learn < 0.19, please replace `n_iter` by `max_iter` in the code example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing fitted scikit-learn estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we trained the logistic regression model as shown above, we now save the pipeline as a serialized object to our local disk so that we can use the fitted classifier in our web application later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieclassifier/classifier.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(pipeline, os.path.join('movieclassifier', 'classifier.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32816\n",
      "-rw-r--r--   1 trung  staff    16M Sep  4 21:22 classifier.pkl\n",
      "drwxr-xr-x   8 trung  staff   272B Sep  4 21:21 \u001b[34m..\u001b[m\u001b[m\n",
      "drwxr-xr-x  12 trung  staff   408B Sep  4 20:41 \u001b[34m.\u001b[m\u001b[m\n",
      "-rw-r--r--   1 trung  staff    50B Sep  4 20:41 requirements.txt\n",
      "drwxr-xr-x   4 trung  staff   136B Sep  4 20:35 \u001b[34mbin\u001b[m\u001b[m\n",
      "-rw-r--r--   1 trung  staff    12B Sep  4 20:32 Procfile\n",
      "-rwxr-xr-x   1 trung  staff   1.0K Sep  3 22:03 \u001b[31mapp.py\u001b[m\u001b[m\n",
      "-rw-r--r--   1 trung  staff   2.0K Sep  3 22:03 movie_classifier.log\n",
      "drwxr-xr-x   4 trung  staff   136B Sep  3 21:53 \u001b[34m__pycache__\u001b[m\u001b[m\n",
      "drwxr-xr-x   5 trung  staff   170B Sep  3 21:53 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-r--r--   1 trung  staff     0B Sep  3 21:53 __init__.py\n",
      "-rw-r--r--   1 trung  staff   253B Sep  3 21:36 preprocess.py\n"
     ]
    }
   ],
   "source": [
    "!ls -thal movieclassifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try loading the classifier and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join('movieclassifier', 'classifier.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n",
      "Probability: 90.96%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "label = {0:'negative', 1:'positive'}\n",
    "\n",
    "example = ['I love this movie']\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
    "      (label[clf.predict(example)[0]], \n",
    "       np.max(clf.predict_proba(example))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying model as a Flask web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [Flask](http://flask.pocoo.org/), a microframework for Web development to expose the model as an API.  \n",
    "\n",
    "Install by \n",
    "\n",
    "    * pip install Flask\n",
    "\n",
    "To run the web applications locally, `cd` into the respective directory (as listed above) and execute the main-application script, for example,\n",
    "\n",
    "    cd ./movie_classifier\n",
    "    python3 app.py\n",
    "    \n",
    "Now, you should see something like\n",
    "    \n",
    "     * Running on http://127.0.0.1:5000/\n",
    "     * Restarting with reloader\n",
    "     \n",
    "in your terminal.\n",
    "Next, open a web browser and enter the address displayed in your terminal (typically http://127.0.0.1:5000/) to view the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud deployment with Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two limitations of the local deployment\n",
    "\n",
    "- Model deployed locally cannot be used by the public. We want to deploy the model on a machine hosted in a cloud such as AWS, Google Cloud, Azure, or interal computing cluster of your company\n",
    "- Flask is mainly for development purpose, not a fully-fledge web server. We need to use a web server which supports Flask for production deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Heroku\n",
    "\n",
    "- Heroku is a cloud platform which offer fully-managed services that let companies build, deliver, monitor and scale apps quickly without having to manage infrastructures.\n",
    "- Heroku runs your apps inside dynos — smart containers on a reliable, fully managed runtime environment. \n",
    "\n",
    "We will use the Python Runtime to deploy our model as a Python web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside the web app code in `app.py` and the model artifact, we need to provide the 3 following files:\n",
    "\n",
    "    - requirements.txt: libraries to install in the run time environment\n",
    "    - Procfile: configure the start script\n",
    "    - bin/web: the start script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.14.3\n",
      "scipy==1.1.0\n",
      "pandas==0.23.0\n",
      "scikit-learn==0.19.1\n",
      "gunicorn==19.9.0\n",
      "Babel==0.9.6\n",
      "click==6.7\n",
      "docutils==0.11\n",
      "Flask==0.12.2\n",
      "itsdangerous==0.24\n",
      "Jinja2==2.6\n",
      "MarkupSafe==0.11\n",
      "nose==1.3.0\n",
      "Pygments==1.5\n",
      "simplejson==3.2.0\n",
      "Sphinx==1.1.3\n",
      "virtualenv==13.1.0\n",
      "Werkzeug==0.14.0\n"
     ]
    }
   ],
   "source": [
    "!cat movieclassifier/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These libraries will be installed by Heroku on the machine where the web app is hosted. They must be specified in the file named `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web: bin/web"
     ]
    }
   ],
   "source": [
    "!cat movieclassifier/Procfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Procfile tells Heroku to run the script in `bin/web` to start the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python app.py &\n",
      "gunicorn -b '0.0.0.0:'$PORT --log-level INFO app:app"
     ]
    }
   ],
   "source": [
    "!cat movieclassifier/bin/web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the start script, we run the Flask application and gunicorn web server which will manage load and route request to the Flask app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live demo to show how to deploy an app. It's as simple as pushing code to a git repo! The repo for this purpose can be cloned from [this repository](https://github.com/trungngv/heroku-python-ml-example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the model API, open your browser and paste the following link:\n",
    "\n",
    "https://movie-classifier.herokuapp.com/review?text=i%20love%20this%20movie\n",
    "\n",
    "You should see the output `{\"sentiment\": \"positive\"}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Amazon SageMaker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live walk through + see the notebook `sagemaker_telecom_customer_churn.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Services \n",
    "\n",
    "Instead of building models, we can use services provided by others. This is becoming more and more popular as AI is being more democratized. \n",
    "\n",
    "## Main service providers:\n",
    "- Google\n",
    "- Microsoft\n",
    "- IBM \n",
    "- Amazon \n",
    "- Other vendors with specialized solutions\n",
    "\n",
    "## Cognitive services:\n",
    "- Natural language\n",
    "    - Sentiment analysis\n",
    "    - Keyphrases detection\n",
    "    - Entity recognition / identification\n",
    "    - Language detection\n",
    "    - Content classification\n",
    "    - Topic modelling\n",
    "    - Relation detection\n",
    "- Computer Vision\n",
    "    - Image classification\n",
    "    - Objects detection\n",
    "    - Scene and activity recognition\n",
    "    - Celebrity recognition\n",
    "    - Landmark recognition\n",
    "    - Optical character recognition (OCR)\n",
    "    - Handwriting recognition\n",
    "    - Face detection\n",
    "    - Person identification \n",
    "    - Emotion recognition / facial analysis\n",
    "    - Similar face recognition and grouping\n",
    "    - Logo detection\n",
    "- Speech\n",
    "    - Speech-to-text\n",
    "    - Text-to-speech\n",
    "    - Translation\n",
    "    \n",
    "## API made easy with Postman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.getpostman.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
